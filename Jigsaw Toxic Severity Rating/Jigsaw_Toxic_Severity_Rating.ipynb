{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9MxeW4fEZFf"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        " \n",
        "!pip3 install --upgrade --force-reinstall --no-deps kaggle\n",
        " \n",
        "!mkdir ~/.kaggle  \n",
        "!cp ./gdrive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n31Zk8rMGias"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-text\n",
        "!pip install -q tf-models-official==2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORn_vTh5EfDu"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-severity-rating\n",
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
        "!kaggle datasets download -d julian3833/jigsaw-unintended-bias-in-toxicity-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsCVOwdAEsKa"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!mkdir data1\n",
        "!mkdir data2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVQpGkpHEvYz"
      },
      "outputs": [],
      "source": [
        "!unzip jigsaw-toxic-severity-rating.zip -d data\n",
        "!unzip jigsaw-toxic-comment-classification-challenge -d data1\n",
        "!unzip jigsaw-unintended-bias-in-toxicity-classification -d data2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvnQr4i49vFD"
      },
      "outputs": [],
      "source": [
        "!unzip data1/train.csv.zip -d data1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kgkbNRXE728"
      },
      "outputs": [],
      "source": [
        "import sklearn as sk\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "from official import nlp\n",
        "from official.modeling import tf_utils\n",
        "from official import nlp\n",
        "from official.nlp import bert\n",
        "\n",
        "# Load the required submodules\n",
        "import official.nlp.optimization\n",
        "import official.nlp.bert.bert_models\n",
        "import official.nlp.bert.configs\n",
        "import official.nlp.bert.run_classifier\n",
        "import official.nlp.bert.tokenization\n",
        "import official.nlp.data.classifier_data_lib\n",
        "import official.nlp.modeling.losses\n",
        "import official.nlp.modeling.models\n",
        "import official.nlp.modeling.networks\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJONumdyFjfK"
      },
      "outputs": [],
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-12_H-768_A-12' \n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'electra_large':\n",
        "        'https://tfhub.dev/google/electra_large/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "    'lambert_en_uncased_L-24_H-1024_A-16':\n",
        "        'https://tfhub.dev/tensorflow/lambert_en_uncased_L-24_H-1024_A-16/2',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_large':\n",
        "        'https://tfhub.dev/google/electra_large/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'lambert_en_uncased_L-24_H-1024_A-16':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEIRfbeIHK01"
      },
      "outputs": [],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBpI9QcZZryX"
      },
      "outputs": [],
      "source": [
        "tf.debugging.set_log_device_placement(False)\n",
        "gpus = tf.config.list_logical_devices('GPU')\n",
        "strategy = tf.distribute.MirroredStrategy(gpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgG2zxIl9TIS"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "snowball = SnowballStemmer(language='english')\n",
        "\n",
        "def transform(input_string : tf.Tensor):\n",
        "  s = input_string.numpy().decode('utf-8')\n",
        "  s = re.sub('[^A-Za-z0-9]+', ' ', s).lower().split()\n",
        "  s = [i for i in s if i not in stop_words]\n",
        "  s = [snowball.stem(i) for i in s]\n",
        "  s = ' '.join(s)\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDG20OgmdfJO"
      },
      "outputs": [],
      "source": [
        "def transform_pd(input_string):\n",
        "  s = re.sub('[^A-Za-z0-9]+', ' ', input_string).lower().split()\n",
        "  s = [i for i in s if i not in stop_words]\n",
        "  s = [snowball.stem(i) for i in s]\n",
        "  s = ' '.join(s)\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDPciXhWKLE8"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('data2/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0VpFBMquk7E"
      },
      "outputs": [],
      "source": [
        "data = tf.data.Dataset.from_tensor_slices((train['comment_text'], train['target']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist = np.linspace(0, 1, num=10)\n",
        "dist = np.column_stack([dist[:-1:], dist[1::]])"
      ],
      "metadata": {
        "id": "3dqcdDN19t3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip = []\n",
        "pl = []\n",
        "for i in dist:\n",
        "  ip.append(train[(train['target'] >= i[0]) & (train['target'] < i[1])].shape[0] / train.shape[0])\n",
        "  pl.append(1 - train[(train['target'] >= i[0]) & (train['target'] < i[1])].shape[0] / train.shape[0])\n",
        "ip = tf.convert_to_tensor(np.array(ip))\n",
        "pl = np.array(pl)\n",
        "pl = tf.convert_to_tensor(pl / pl.sum())\n",
        "dist = tf.convert_to_tensor(dist)"
      ],
      "metadata": {
        "id": "Sd00NDkcEwQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl"
      ],
      "metadata": {
        "id": "ISrZLwSu5HlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = np.linspace(0, 1, num=10)\n",
        "dist = tf.convert_to_tensor(dist[:-1:])"
      ],
      "metadata": {
        "id": "9MIzBB3wmu6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist"
      ],
      "metadata": {
        "id": "LRocipFu3sKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def find(x : tf.Tensor):\n",
        "  return tf.cast(tf.reduce_sum(tf.cast(tf.less_equal(dist, x), dtype=tf.float64)) - 1, dtype=tf.int32)"
      ],
      "metadata": {
        "id": "pTDLN2GNJBIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find(tf.constant(1, dtype=tf.float64))"
      ],
      "metadata": {
        "id": "R_T4H1pqhkGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.rejection_resample(lambda x, y: find(y), target_dist=pl).map(lambda a, b: b)"
      ],
      "metadata": {
        "id": "GTnPuPNH8fJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sample = data.take(10000).map(lambda x, y: y)"
      ],
      "metadata": {
        "id": "PSNwWOMfwOHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sample = list(data_sample.as_numpy_iterator())"
      ],
      "metadata": {
        "id": "w1rXFCW-0DCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'target': data_sample})"
      ],
      "metadata": {
        "id": "e4wTiImj0oYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].hist(bins=20)"
      ],
      "metadata": {
        "id": "dZgMewNg02OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uWXRFavj-NQ"
      },
      "outputs": [],
      "source": [
        "data = data.batch(32).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')"
      ],
      "metadata": {
        "id": "Bf3v1zG5U_iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1zDolBiIXNO"
      },
      "outputs": [],
      "source": [
        "def get_model_v_1():\n",
        "  with strategy.scope():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(200, activation=tf.nn.elu)(net)\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(200, activation=tf.nn.elu)(net)\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(net)\n",
        "    model = tf.keras.Model(text_input, net)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='MAE', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_v_2():\n",
        "  with strategy.scope():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder = hub.KerasLayer(\"https://tfhub.dev/google/sentence-t5/st5-3b/1\", trainable=True, input_shape=[], dtype=tf.string)\n",
        "    net = encoder(text_input)\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(200, activation=tf.nn.elu)(net)\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(200, activation=tf.nn.elu)(net)\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(net)\n",
        "    model = tf.keras.Model(text_input, net)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='MAE', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "    return model"
      ],
      "metadata": {
        "id": "EzVt3kxzKjmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fC33yesIPCD"
      },
      "outputs": [],
      "source": [
        "model = get_model_v_2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDSQQI-hYnSn"
      },
      "outputs": [],
      "source": [
        "model.fit(x=data, epochs=1, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "o_qWchYDMU7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa_4vCvcE-9e"
      },
      "outputs": [],
      "source": [
        "comments = pd.read_csv('data/comments_to_score.csv')\n",
        "comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA5v-s6TKHTk"
      },
      "outputs": [],
      "source": [
        "comments['transform_text'] = comments['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrKjs_HUK7En"
      },
      "outputs": [],
      "source": [
        "test_y = model.predict(comments['transform_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYMp6IERLfIf"
      },
      "outputs": [],
      "source": [
        "comments['target'] = test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI31sZL6JGKS"
      },
      "outputs": [],
      "source": [
        "test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIWrr7T6T88B"
      },
      "outputs": [],
      "source": [
        "comments.iloc[0:7:]['transform_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mMl9KJERB6G"
      },
      "outputs": [],
      "source": [
        "text = comments.iloc[0:7:]['transform_text']\n",
        "print(text)\n",
        "for layer in model.layers[0:3]:\n",
        "  text = layer(text)\n",
        "  print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDW5j4mZSoKt"
      },
      "outputs": [],
      "source": [
        "text['pooled_output'][0] - text['pooled_output'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_jUJJuPL6fs"
      },
      "outputs": [],
      "source": [
        "comments[comments['target'] > 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFi5_ZS2Lmh4"
      },
      "outputs": [],
      "source": [
        "comments.to_csv('result.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69rhXwsvG74G"
      },
      "outputs": [],
      "source": [
        "validation = pd.read_csv('data/validation_data.csv')\n",
        "validation.iloc[0]['more_toxic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D92Bu45vSRiN"
      },
      "outputs": [],
      "source": [
        "rates_less_toxic = []\n",
        "rates_more_toxic = []\n",
        "for i in range(len(validation)):\n",
        "  less_toxic = validation.iloc[i]['less_toxic']\n",
        "  more_toxic = validation.iloc[i]['more_toxic']\n",
        "  rate_less_toxic = comments[comments['text'] == less_toxic]['target']\n",
        "  rate_more_toxic = comments[comments['text'] == more_toxic]['target']\n",
        "  if len(rate_less_toxic) > 0 and len(rate_more_toxic) > 0:\n",
        "    rates_less_toxic.append(rate_less_toxic.iloc[0])\n",
        "    rates_more_toxic.append(rate_more_toxic.iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5iJU-qjWYB5"
      },
      "outputs": [],
      "source": [
        "rates_less_toxic = np.array(rates_less_toxic)\n",
        "rates_more_toxic = np.array(rates_more_toxic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUBDB0cmW8L7"
      },
      "outputs": [],
      "source": [
        "d = rates_more_toxic - rates_less_toxic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'d': d, 'rates_more_toxic': rates_more_toxic, 'rates_less_toxic': rates_less_toxic})"
      ],
      "metadata": {
        "id": "blc5gF1mfBy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['rates_less_toxic'] < 0.2]"
      ],
      "metadata": {
        "id": "UxEqkSuhhoa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist()"
      ],
      "metadata": {
        "id": "96eu89-HfPxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAGKelp2XEBF"
      },
      "outputs": [],
      "source": [
        "d[d > 0].shape[0] / d.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyhbt9kUnk3k"
      },
      "outputs": [],
      "source": [
        "d[d >= 0].shape[0] / d.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_1')"
      ],
      "metadata": {
        "id": "uMpve7hEdmg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model_1.zip  model_1/"
      ],
      "metadata": {
        "id": "J3eYpmyaeGut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv model_1.zip /content/gdrive/MyDrive/"
      ],
      "metadata": {
        "id": "JT1anJIUMI5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phncnSKEEZoB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "jigsaw-toxic-severity-rating.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}